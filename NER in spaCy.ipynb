{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition in spaCy\n",
    "Kate Riesbeck  \n",
    "19 May 2020  \n",
    "  \n",
    "   \n",
    "This notebook reviews named entity recognition (NER) in spaCy with:\n",
    "* a pretrained spaCy model\n",
    "* spaCy lookup\n",
    "* a custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7ffd3b0a97f0>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7ffd3b099d60>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7ffd3b0b32e0>)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current pipeline\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add entities with spaCy lookup\n",
    "\n",
    "pip install spacy-lookup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spacy-lookup matches on token text (not a statistical prediction)\n",
    "\n",
    "can be used alone or added to a pipeline with an existing model \n",
    "\n",
    "https://github.com/mpuig/spacy-lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_lookup import Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7ffd3b0a97f0>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7ffd3b099d60>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7ffd3b0b32e0>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current pipeline\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents = [\"Donald Trump\" , \"Barack Obama\" , \"George W. Bush\" , \"Bill Clinton\" , \"George H.W. Bush\" , \"Ronald Reagan\" , \"Jimmy Carter\" , \"Gerald Ford\" , \"Richard Nixon\" , \"Lyndon B. Johnson\" , \"John F. Kennedy\" , \"Dwight D. Eisenhower\", \"Harry S. Truman\" , \"Franklin D. Roosevelt\" , \"Herbert Hoover\" , \"Calvin Coolidge\" , \"Warren G. Harding\" , \"Woodrow Wilson\" , \"Howard Taft\" , \"Theodore Roosevelt\" , \"William McKinley\" , \"Grover Cleveland\" , \"Benjamin Harrison\" , \"Grover Cleveland\" , \"Chester A. Arthur\" , \"James Garfield\" , \"Rutherford B. Hayes\" , \"Ulysses S. Grant\" , \"Andrew Johnson\" , \"Abraham Lincoln\" , \"James Buchanan\" , \"Franklin Pierce\" , \"Millard Fillmore\", \"Zachary Taylor\" , \"James K. Polk\" , \"John Tyler\" , \"William Henry Harrison\" , \"Martin Van Buren\" , \"Andrew Jackson\" , \"John Quincy Adams\" , \"James Monroe\" , \"James Madison\" , \"Thomas Jefferson\" , \"John Adams\" , \"George Washington\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Donald Trump',\n",
       " 'Barack Obama',\n",
       " 'George W. Bush',\n",
       " 'Bill Clinton',\n",
       " 'George H.W. Bush',\n",
       " 'Ronald Reagan',\n",
       " 'Jimmy Carter',\n",
       " 'Gerald Ford',\n",
       " 'Richard Nixon',\n",
       " 'Lyndon B. Johnson',\n",
       " 'John F. Kennedy',\n",
       " 'Dwight D. Eisenhower',\n",
       " 'Harry S. Truman',\n",
       " 'Franklin D. Roosevelt',\n",
       " 'Herbert Hoover',\n",
       " 'Calvin Coolidge',\n",
       " 'Warren G. Harding',\n",
       " 'Woodrow Wilson',\n",
       " 'Howard Taft',\n",
       " 'Theodore Roosevelt',\n",
       " 'William McKinley',\n",
       " 'Grover Cleveland',\n",
       " 'Benjamin Harrison',\n",
       " 'Grover Cleveland',\n",
       " 'Chester A. Arthur',\n",
       " 'James Garfield',\n",
       " 'Rutherford B. Hayes',\n",
       " 'Ulysses S. Grant',\n",
       " 'Andrew Johnson',\n",
       " 'Abraham Lincoln',\n",
       " 'James Buchanan',\n",
       " 'Franklin Pierce',\n",
       " 'Millard Fillmore',\n",
       " 'Zachary Taylor',\n",
       " 'James K. Polk',\n",
       " 'John Tyler',\n",
       " 'William Henry Harrison',\n",
       " 'Martin Van Buren',\n",
       " 'Andrew Jackson',\n",
       " 'John Quincy Adams',\n",
       " 'James Monroe',\n",
       " 'James Madison',\n",
       " 'Thomas Jefferson',\n",
       " 'John Adams',\n",
       " 'George Washington']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new \"entity\" pipeline component\n",
    "\n",
    "# new labels can be added with via a list, dictionary, or file\n",
    "\n",
    "new_entities = Entity(keywords_list=presidents, label='PRES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new entity component before the existing 'ner' pipeline\n",
    "nlp.add_pipe(new_entities, before='ner', name='presidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7ffd3b0a97f0>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7ffd3b099d60>),\n",
       " ('presidents', <spacy_lookup.Entity at 0x7ffd39273580>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7ffd3b0b32e0>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George H.W. Bush 5 21 PRES\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"When George H.W. Bush was elected.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Bush 5 16 PERSON\n"
     ]
    }
   ],
   "source": [
    "# limitation -- only finds exact matches\n",
    "\n",
    "doc = nlp(u\"When George Bush was elected.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: If you're using an existing model, make sure to mix in examples of\n",
    "# other entity types that spaCy correctly recognized before. Otherwise, your\n",
    "# model might learn the new type, but \"forget\" what it previously knew.\n",
    "# https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DataTurks-Engg/Entity-Recognition-In-Resumes-SpaCy\n",
    "\n",
    "# spaCy’s models are statistical and every “decision” they make whether a word is a named entity is a prediction. \n",
    "# This prediction is based on the examples the model has seen during training.\n",
    "\n",
    "# The model is then shown the unlabelled text and will make a prediction. \n",
    "# Because we know the correct answer, we can give the model feedback on its prediction in the form of an error gradient of the loss function that calculates the difference between the training example and the expected output. \n",
    "# The greater the difference, the more significant the gradient and the updates to our model.\n",
    "\n",
    "# When training a model, we don’t just want it to memorise our examples — \n",
    "# we want it to come up with theory that can be generalised across other examples. \n",
    "# After all, we don’t just want the model to learn that this one instance of “Amazon” right here is a company — \n",
    "# we want it to learn that “Amazon”, in contexts like this, is most likely a company. \n",
    "# In order to tune the accuracy, we process our training examples in batches, \n",
    "# and experiment with minibatch sizes and dropout rates.\n",
    "\n",
    "# Of course, it’s not enough to only show a model a single example once. \n",
    "# Especially if you only have few examples, you’ll want to train for a number of iterations. \n",
    "# At each iteration, the training data is shuffled to ensure the model doesn’t make any generalisations \n",
    "# based on the order of examples.\n",
    "\n",
    "# Another technique to improve the learning results is to set a dropout rate, \n",
    "# a rate at which to randomly “drop” individual features and representations. \n",
    "# This makes it harder for the model to memorise the training data. \n",
    "# For example, a 0.25dropout means that each feature or internal representation has a 1/4 likelihood of being dropped. \n",
    "# We train the model for 10 epochs and keep the dropout rate as 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results and Evaluation of the model :\n",
    "The model is tested on 20 resumes and the predicted summarized resumes are stored as separate .txt files for each resume.\n",
    "\n",
    "For each resume on which the model is tested, we calculate the accuracy score, precision, recall and f-score for each entity that the model recognizes. The values of these metrics for each entity are summed up and averaged to generate an overall score to evaluate the model on the test data consisting of 20 resumes. The entity wise evaluation results can be observed below . It is observed that the results obtained have been predicted with a commendable accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prodigy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
